# Adversarial Search

## Minimax Search

- value of state: the best achievable utility(outcome) from that state

- Minimax Search![](https://cdn.luogu.com.cn/upload/image_hosting/9bh52x20.png)

- problem: 

    - a deterministic, zero-sum game
      - one player will maximize the result
      - the other player will minimize the result
    - two players alternate turns
    - two players always take the optimal move

- implementation:

  ```
  def value(state):
  	if the state is a terminal state: return the state's utility
  	if the next agent is MAX: return max-value(state)
  	if the next agent is MIN: return min-value(state)
  
  def max-value(state):
  	initialize v = -inf
  	for each successor of state
  		v = max(v,value(successor))
  	return v
  	
  def max-value(state):
  	initialize v = inf
  	for each successor of state
  		v = min(v,value(successor))
  	return v
  ```
 - complexity:

    - Time: $O(b^m)$
    - Space: $O(bm)$

### Alpha-Beta Pruning

- idea: (take min-agent version as an example)

  - when searching through all its child, if we found a value is guaranteed to be greater than the min-cost of previous children, just skip it

- implementation:

  ```
  def max-value(state,alpha,beta):
  	initialize v = -inf
  	for each successor of state
  		v = max(v,value(successor))
  		if v >= beta: return v
  		alpha = max(alpha, v)
  	return v
  	
  def min-value(state,alpha,beta):
  	initialize v = inf
  	for each successor of state
  		v = min(v,value(successor))
  		if v <= alpha: return v
  		beta = min(beta, v)
  	return v
  ```

- Complexity(time): $O(b^{\frac{m}{2}})$

### Depth-limit Search

- solution:
  - search only a limited depth in the tree
  - replace the terminal real utilities with an evaluation function for non-terminal positions
  
- evaluation function: the  most common way to design for an evaluation function is
  $$
  Eval(state) =  w_1f_1(state)+w_2f_2(state)+...+w_nf_n(state)\\

  $$

  - $w$ stands for the weight
  - $f_i(state)$ stands for a feature corresponds to a feature extracted from the state 


## Expectimax Search

- problem: a game with uncertainty

- Expectimax search model:

  ![](https://cdn.luogu.com.cn/upload/image_hosting/6cpw6cw3.png)

  - max-node: just like max-node in Minimax Search
  - chance-node: like min-node but the outcome is uncertain
    - we use the **expected** utilities to calculate the chance-node's value

- Implementation:

  ```
  def value(state):
  	if state is a terminal state: return the state's utility
  	if next agent is MAX: return max-value(state)
  	if next agent is EXP: return exp-value(state)
  	
  def max-value(state):
  	initialize v = -inf
  	for each successor of state:
  		v = max(v,value(successor))
  	return v
  	
  def exp-value(state):
  	initialize v = 0
  	for each successor of state:
  		v += possibility(successor) * value(successor)
  	return v
  ```

- Improvement: depth-limited search

## Multiple-agent Utility

- problem: 

  - game is not zero-sum
  - or have multiple players

- notation:

  - preference: $A\succ B$
  - indifference: $A\sim B$

- terminology:

  - prize: just as outcome or value of leaf node, $A$,$B$,etc.
  - lottery: situations with uncertain prizes
    - eg. $L=[p,A; (1-p),B]$

- Constraints of rational preferences (Axiom of Rationality):

  - Transitivity: $A\succ B,B\succ C\to A\succ C$
  - Orderability: $(A\succ B) \lor (B\succ A) \lor (A\sim B)$
  - Continuity: $A\succ B\succ C\to \exist p,[p,A;(1-p),C]\sim B$
  - Substitutability: $A\sim B\to [p,A;(1-p),C]\sim [p,B;(1-p),C]$
  - Monotonicity: $A\succ B\to (p\ge q\leftrightarrow [p,A;(1-p),B]\succeq [p,B;(1-p),A])$

- Rational Preference imply behavior describable as maximization of expected utility

- MEU principle: if preference satisfies the constraints, there exists a real-value function satisfies
  $$
  U(A)\ge U(B) \leftrightarrow A\succeq B\\
  U([p_1,S_1],[p_2,S_2],...,[p_n,S_n])=\sum p_iU(S_i)
  $$

## Conclusion

- The minimax value can never be strictly greater than expectimax value for the same tree

  - The utility at a node under expectimax is always at least as high as the utility of the same node under minimax.
- 
   